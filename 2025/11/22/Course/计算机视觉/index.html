<!DOCTYPE html><html lang="zh" theme-mode="dark"><head><meta charset="UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1.0"><title>计算机视觉-兴军亮 | Nervld的小窝</title><link rel="icon" type="image/x-icon" href="/favicon.ico"><link rel="preload" as="font" crossorigin="anonymous" href="/font/Bender.ttf"><link rel="preload" as="font" crossorigin="anonymous" href="/font/BenderLight.woff2"><link rel="preload" as="font" crossorigin="anonymous" href="/font/JetBrainsMono-Regular.woff2"><link rel="stylesheet" href="/css/arknights.css"><style>@font-face {
  font-family: Bender;
  src: local('Bender'), url("/font/Bender.ttf"), url("/font/Bender.otf");
}
@font-face {
  font-family: BenderLight;
  src: local('BenderLight'), url("/font/BenderLight.ttf");
}
@font-face {
  font-family: 'JetBrains Mono';
  src: local('JetBrains Mono'), url('/font/JetBrainsMono-Regular.woff2') format('woff2');
}
</style><meta name="page-config" content="{&quot;code_fold&quot;:null}"><script class="pjax-js">var config = {"root":"/","code_fold":15,"search":{"preload":false,"activeHolder":"键入以继续","blurHolder":"数据检索","noResult":"无 $0 相关数据"},"code":{"codeInfo":"$0 - $1 行","copy":"复制"}};
var page_config = {
  code_fold: null
};
function updatePageConfig() {
  var newPageConfig = document.querySelector('meta[name="page-config"]');
  if (newPageConfig) {
    page_config = JSON.parse(newPageConfig.content);
  }
}
document.addEventListener('pjax:complete', function() { updatePageConfig(); });
updatePageConfig();</script><link type="text/css" rel="stylesheet" href="/lib/encrypt/hbe.style.css"><script src="//unpkg.com/mermaid@10.5.0/dist/mermaid.min.js"></script><link type="text/css" rel="stylesheet" href="//unpkg.com/lightgallery@2.7.1/css/lightgallery.css"><link type="text/css" rel="stylesheet" href="//unpkg.com/lightgallery@2.7.1/css/lg-zoom.css"><link type="text/css" rel="stylesheet" href="//unpkg.com/lightgallery@2.7.1/css/lg-thumbnail.css"><link type="text/css" rel="stylesheet" href="/lib/fontawesome/css/all.min.css"><script>if (window.localStorage.getItem('theme-mode') === 'light')
 document.documentElement.setAttribute('theme-mode', 'light')
if (window.localStorage.getItem('theme-mode') === 'dark')
 document.documentElement.setAttribute('theme-mode', 'dark')</script><style>@font-face {
 font-family: BenderLight;
 src: local('Bender'), url("/font/BenderLight.woff2") format('woff2');
}
@font-face {
 font-family: 'JetBrains Mono';
 src: local('JetBrains Mono'), url('/font/JetBrainsMono-Regular.woff2') format('woff2');
}</style><style>:root {
 --dark-background: url('/img/mybg3.png');
 --light-background: url('/img/bk.jpg');
 --theme-encrypt-confirm: '确认'
}</style><script defer src="/js/arknights.js"></script><script defer src="/js/search.js"></script><script defer src="https://vercount.one/js"></script><script defer type="module">import mermaid from '//unpkg.com/mermaid@10.5.0/dist/mermaid.esm.mjs';
window.mermaid = mermaid;
code.paintMermaid();
</script><script async src="//unpkg.com/lightgallery@2.7.1/lightgallery.min.js"></script><script async src="//unpkg.com/lightgallery@2.7.1/plugins/zoom/lg-zoom.min.js"></script><script async src="//unpkg.com/lightgallery@2.7.1/plugins/thumbnail/lg-thumbnail.min.js"></script><script async src="/lib/encrypt/hbe.js"></script><script async src="/js/pjax.js"></script><script class="pjax-js">reset= () => {document.querySelector('.lg-container')?.remove()
lightGallery(document.getElementById('post-bg'), {
  plugins: [lgZoom,lgThumbnail],
  selector: '.item-img'})}</script><script>window.addEventListener("load",() => {pjax = new Pjax({
 cacheBust: false,
 selectors: ['title','article','#aside-block','.pjax-js','data-pjax','.vercount','meta[name=page-config]'],
 switches: {'article': Pjax.switches.sideBySide},
 switchesOptions: {
   'article': {
     classNames: {
       remove: "pjax-out",
       add: "pjax-in"
     }
   }
 }
});
document.addEventListener("pjax:complete", reset);document.addEventListener('pjax:success', _ => {
 const script = document.createElement('script');
 script.src = 'https://vercount.one/js';
 document.head.appendChild(script);
});reset()})</script><script class="pjax-js">reset= () => {document.querySelector('.lg-container')?.remove()
lightGallery(document.getElementById('post-bg'), {
  plugins: [lgZoom,lgThumbnail],
  selector: '.item-img'})}</script><script>window.addEventListener("load",() => {pjax = new Pjax({
 cacheBust: false,
 selectors: ['title','article','#aside-block','.pjax-js','data-pjax','.vercount','meta[name=page-config]'],
 switches: {'article': Pjax.switches.sideBySide},
 switchesOptions: {
   'article': {
     classNames: {
       remove: "pjax-out",
       add: "pjax-in"
     }
   }
 }
});
document.addEventListener("pjax:complete", reset);document.addEventListener('pjax:success', _ => {
 const script = document.createElement('script');
 script.src = 'https://vercount.one/js';
 document.head.appendChild(script);
});reset()})</script><meta name="generator" content="Hexo 7.3.0"></head><body><div class="loading" style="opacity: 0;"><div class="loadingBar left"></div><div class="loadingBar right"></div></div><main><header class="closed"><div class="navBtn"><i class="navBtnIcon"><span class="navBtnIconBar"></span><span class="navBtnIconBar"></span><span class="navBtnIconBar"></span></i></div><nav><div class="navItem" id="search-header"><span class="navItemTitle"><input autocomplete="off" autocorrect="off" autocapitalize="none" placeholder="数据检索" spellcheck="false" maxlength="50" type="text" id="search-input"></span></div><div class="navItem" id="search-holder"></div><div class="search-popup" tabindex="0"><div id="search-result"></div></div><ol class="navContent"><li class="navItem"><a class="navBlock" href="/"><span class="navItemTitle">Home</span></a></li><li class="navItem" matchdata="categories,tags"><a class="navBlock" href="/archives/"><span class="navItemTitle">Archives</span></a></li><li class="navItem"><a class="navBlock" href="/about/"><span class="navItemTitle">About</span></a></li></ol></nav></header><article><div id="post-bg"><div id="post-title"><h1>计算机视觉-兴军亮</h1><div id="post-info"><span>文章发布时间: <div class="control"><time datetime="2025-11-22T03:45:41.828Z" id="date"> 2025-11-22</time></div></span><br><span>最后更新时间: <div class="control"><time datetime="2026-01-07T10:28:32.368Z" id="updated"> 2026-01-07</time></div></span><br><span>文章总字数: <div class="control">14.7k</div></span><br><span>预计阅读时间: <div class="control">55 分钟</div></span><br><span id="vercount_container_page_pv">页面浏览: <span class="control" id="vercount_value_page_pv">加载中...</span></span></div></div><hr><div id="post-content"><h1 id="计算机视觉基础-第2讲"><a href="#计算机视觉基础-第2讲" class="headerlink" title="计算机视觉基础(第2讲)"></a>计算机视觉基础(第2讲)</h1><p><strong>梯度下降法：</strong> 梯度下降法是一种通过迭代方式寻找函数最小值的优化算法，其核心在于沿着目标函数梯度的反方向逐步调整参数。<br><strong>公式：</strong> $\theta_{n+1} &#x3D; \theta_n - \alpha \cdot J’(\theta_n)$每一个分量的偏导数执行这个梯度下降公式。</p>
<p><strong>最小二乘法：</strong> 通过最小化误差平方和来寻找数据最佳函数匹配的数学优化技术。<br>损失函数：$L(\beta_0, \beta_1) &#x3D; \sum_{i&#x3D;1}^{n} (y_i - \hat{y}<em>i)^2 &#x3D; \sum</em>{i&#x3D;1}^{n} \big( y_i - (\beta_0 + \beta_1 x_i) \big)^2$，一元线性回归有解析解，$y&#x3D;β_0​+β_1​x$，最优参数为：$\beta_1 &#x3D; \frac{\sum_{i&#x3D;1}^n (x_i - \bar{x})(y_i - \bar{y})}{\sum_{i&#x3D;1}^n (x_i - \bar{x})^2}, \quad \beta_0 &#x3D; \bar{y} - \beta_1 \bar{x}$，其中其中$\bar{x},\bar{y}$是样本均值。</p>
<p><strong>信息熵：</strong> 对于一个离散随机变量 X，其可能取值为 x1​,x2​,…,xn​，对应的概率为 P(xi​)，则<strong>香农熵</strong>为$H(X) &#x3D; -\sum_{i&#x3D;1}^{n} P(x_i) \log_2 P(x_i)$，交叉熵为$H(p, q) &#x3D; -\sum_{i&#x3D;1}^{n} p(x_i) \log q(x_i)$，其中$x_i$为离散随机变量（标签）的取值。</p>
<p><strong>傅里叶变换：</strong> 是一种将信号从时域（或空域）转换到频域的数学工具，其核心思想是将任意复杂信号分解为一系列不同频率的正弦波（或复指数）的叠加。</p>
<p><strong>模式识别主要分类：</strong></p>
<ul>
<li><strong>贝叶斯决策:</strong> 最小错误率贝叶斯决策，最小风险贝叶斯决策；模式识别效果的度量等</li>
<li><strong>概率密度函数估计:</strong> 最大似然估计、贝叶斯估计、非参数估计等</li>
<li><strong>特征提取选择及降维:</strong> 特征距离度量、特征选择算法、特征选择度量、主成分分析、KL变换等</li>
<li><strong>概率图模型:</strong> 无向图（马尔可夫网），有向图（贝叶斯网络、隐马尔可夫网络HMM）等</li>
<li><strong>线性和非线性分类器:</strong> ​ LDA、Perception、LR、SVM；分段线性分类器、二次判别函数、MLP、Kernel SVM等</li>
<li><strong>非参数与集成学习:</strong> 近邻法、决策树、随机森林、Bagging、Boosting</li>
<li><strong>非监督学习与聚类:</strong> ​ 基于模型的聚类、混合模型、动态聚类、模糊聚类、分级聚类、自组织映射神经网络、一致聚类</li>
<li><strong>模式识别系统的评价:</strong> ​ 监督模式识别的错误率估计、有限样本下错误率的区间估计、非监督模式识别的性能评价等</li>
</ul>
<p>贝叶斯决策：贝叶斯决策是统计模式识别中的核心理论框架，基于贝叶斯定理，在已知先验概率和类条件概率的情况下，通过计算后验概率来最小化分类错误率或期望风险。</p>
<p><strong>1. 贝叶斯定理公式</strong><br>$P(\omega_i | \mathbf{x}) &#x3D; \frac{P(\mathbf{x} | \omega_i) P(\omega_i)}{P(\mathbf{x})}$其中：</p>
<ul>
<li>$P(\omega_i | \mathbf{x})$：后验概率（观测到特征$\mathbf{x}$后，样本属于类别$\omega_i$的概率）</li>
<li>$P(\mathbf{x} | \omega_i)$：类条件概率（在类别$\omega_i$下出现特征$\mathbf{x}$的概率）</li>
<li>$P(\omega_i)$：先验概率（类别$\omega_i$出现的初始概率）</li>
<li>$P(\mathbf{x}) &#x3D; \sum_{j&#x3D;1}^{c} P(\mathbf{x} | \omega_j) P(\omega_j)$：证据因子（归一化常数）</li>
</ul>
<p><strong>2. 最小错误率贝叶斯决策规则</strong><br>$\text{若 } P(\omega_i | \mathbf{x}) &#x3D; \max_{j&#x3D;1,2,\cdots,c} P(\omega_j | \mathbf{x}) \text{，则决策 } \mathbf{x} \in \omega_i$等价形式（常用）：<br>$\text{若 } P(\mathbf{x} | \omega_i) P(\omega_i) &gt; P(\mathbf{x} | \omega_j) P(\omega_j) \quad \text{对所有 } j \neq i \text{，则决策 } \mathbf{x} \in \omega_i$</p>
<p><strong>3. 最小风险贝叶斯决策规则</strong><br>$\text{若 } R(\alpha_i | \mathbf{x}) &#x3D; \min_{j&#x3D;1,2,\cdots,c} R(\alpha_j | \mathbf{x}) \text{，则采取决策 } \alpha_i$<br>其中条件风险：$R(\alpha_i | \mathbf{x}) &#x3D; \sum_{j&#x3D;1}^{c} \lambda(\alpha_i, \omega_j) P(\omega_j | \mathbf{x})$，其中$\lambda(\alpha_i, \omega_j)$表示将真实类别$\omega_j$的样本误判为$\omega_i$的损失函数。</p>
<p><strong>特征提取及度量：</strong> 特征提取是将原始数据转换为更易于处理的形式的过程，通常涉及到降维、特征选择和特征变换等步骤。特征度量则是对提取到的特征进行评估和比较的过程，常用的度量方法包括欧氏距离、曼哈顿距离、余弦相似度等。</p>
<p><strong>1. 特征提取方法</strong></p>
<ul>
<li>主成分分析（PCA）：通过线性变换将数据投影到方差最大的方向上，实现降维和去相关。</li>
<li>线性判别分析（LDA）：通过最大化类间散度与类内散度的比值来寻找最佳投影方向。</li>
<li>独立成分分析（ICA）：将多变量信号分解为统计独立的成分，常用于盲源分离。</li>
<li>小波变换：通过多尺度分析提取信号的局部特征，适用于图像处理和信号分析。</li>
</ul>
<p><strong>2. 特征度量方法</strong></p>
<ul>
<li>欧氏距离：衡量两个特征向量之间的直线距离，适用于连续型特征。</li>
<li>曼哈顿距离：计算两个特征向量在各维度上的绝对差值之和，适用于离散型特征。</li>
<li>余弦相似度：通过计算两个特征向量的夹角余弦值来衡量相似性，适用于文本和高维数据。(公式：$ \text{Cosine Similarity} &#x3D; \frac{A \cdot B}{|A| |B|} $)</li>
<li>马氏距离：考虑特征之间的相关性，适用于多变量数据的度量。 (公式：$ D_M(x, y) &#x3D; \sqrt{(x - y)^T S^{-1} (x - y)} $，其中$S$为协方差矩阵)</li>
</ul>
<p><strong>机器学习不同问题及对应的典型计算机视觉任务：</strong></p>
<ul>
<li>监督学习：是机器学习最常见的一种算法学习训练方式。它使用标记数据集来训练算法，以便训练后的算法可以对数据进行分类或准确预测结果。典型任务包括图像分类、目标检测、语音识别等。</li>
<li>无监督学习：指的是用算法来分析并聚类未标记的数据集，以便发现数据中隐藏的模式和规律，而不需要人工干预。 典型任务包括聚类分析、降维、异常检测等。无监督学习更适合处理大量的数据。</li>
<li>强化学习：是一种机器学习技术，它基于反馈的学习方法，对算法执行的正确和不正确行为分别进行奖励 和惩罚的制度，目的是使算法获得最大的累积奖励，从而学会在特定环境下做出最佳决策。 典型任务包括游戏AI、机器人控制、自动驾驶等。</li>
<li>半监督学习：或可称为混合学习，可以说是两全其美的方式。在我们拥有相对较少的标记数据和大量未标记数据的情况下，半监督学习结合了监督学习和无监督学习的优势，可以发挥很好的作用。典型任务包括文本分类、图像识别等。</li>
<li>自监督学习: 不需要人工标注训练数据，它的模型主要训练从大规模的无监督数据中挖掘能够应用于自身的监督信息，从而从输入的一部分数据中去学习另一部分。典型任务包括自然语言处理、计算机视觉等。</li>
</ul>
<p><strong>典型的深度学习网络结构：</strong></p>
<ul>
<li>前馈神经网络：包括全连接层、卷积层、池化层等，用于处理图像、语音等数据。</li>
<li>卷积神经网络：一种前馈神经网络，专门用于处理图像数据，通过卷积层、池化层和全连接层等结构提取图像特征，实现图像分类、目标检测等任务。</li>
<li>循环神经网络：一种前馈神经网络，用于处理序列数据，如文本、语音等，通过循环结构捕捉序列中的时间依赖关系。</li>
<li>长短时记忆网络：一种特殊的循环神经网络，能够有效地捕捉长距离依赖关系，广泛应用于自然语言处理、语音识别等任务。</li>
<li>注意力机制网络：通过引入注意力机制，能够动态地关注输入数据的不同部分，提高模型的表达能力和性能，广泛应用于自然语言处理、计算机视觉等领域。</li>
</ul>
<h1 id="图像的形成-第3讲"><a href="#图像的形成-第3讲" class="headerlink" title="图像的形成(第3讲)"></a>图像的形成(第3讲)</h1><p><strong>人眼成像的基本原理：</strong> 人眼通过角膜和晶状体将光线聚焦在视网膜上，视网膜上的感光细胞将光信号转换为电信号，传递给大脑进行处理和解释。</p>
<p><strong>双视几何</strong>：双视几何是研究两个摄像机视角下同一场景的几何关系的学科，主要涉及摄像机模型、投影变换、立体匹配等内容。其核心概念包括基础矩阵、极线约束和三角测量等。</p>
<ul>
<li>基础矩阵（Fundamental Matrix）：描述两个摄像机视图之间的对应关系，满足极线约束条件。</li>
<li>极线约束（Epipolar Constraint）：在双视几何中，图像点在一个视图中的位置决定了其在另一个视图中的对应极线位置。</li>
<li>三角测量（Triangulation）：通过两个摄像机视图中的对应点，利用几何关系计算三维空间中点的位置。</li>
</ul>
<p><strong>常见的几何仿射变换</strong>：包括平移、旋转、缩放、剪切等变换，这些变换可以通过矩阵运算来表示和实现。</p>
<ul>
<li>平移变换：将图像中的点沿某个方向移动一定距离。矩阵表示为：<br>$\begin{bmatrix}1 &amp; 0 &amp; t_x \ 0 &amp; 1 &amp; t_y \ 0 &amp; 0 &amp; 1\end{bmatrix}$</li>
<li>旋转变换：将图像中的点绕某个中心点旋转一定角度。矩阵表示为：$\begin{bmatrix}\cos\theta &amp; -\sin\theta &amp; 0 \ \sin\theta &amp; \cos\theta &amp; 0 \ 0 &amp; 0 &amp; 1\end{bmatrix}$</li>
<li>缩放变换：将图像中的点沿某个方向缩放一定比例。矩阵表示为：$\begin{bmatrix}s_x &amp; 0 &amp; 0 \ 0 &amp; s_y &amp; 0 \ 0 &amp; 0 &amp; 1\end{bmatrix}$</li>
<li>剪切变换：将图像中的点沿某个方向进行倾斜变换。矩阵表示为：$\begin{bmatrix}1 &amp; k_x &amp; 0 \ k_y &amp; 1 &amp; 0 \ 0 &amp; 0 &amp; 1\end{bmatrix}$</li>
</ul>
<p><strong>光照模型</strong>：光照模型用于描述光线与物体表面相互作用的方式，常见的光照模型包括朗伯反射模型、冯氏反射模型和镜面反射模型等。</p>
<ul>
<li>朗伯反射模型：描述理想漫反射表面，光线均匀地反射到所有方向。公式为：$L &#x3D; k_d I \max(0, \cos\theta)$，其中$k_d$为漫反射系数，$I$为入射光强度，$\theta$为入射光与表面法线的夹角。</li>
<li>冯氏反射模型：描述具有一定光泽的表面，结合了漫反射和镜面反射。公式为：$L &#x3D; k_d I \max(0, \cos\theta) + k_s I \max(0, \cos\alpha)^n$，其中$k_s$为镜面反射系数，$\alpha$为视角与反射方向的夹角，$n$为高光指数。</li>
</ul>
<p><strong>摄像机的成像过程和主要参数</strong>：摄像机通过镜头将光线聚焦在图像传感器上，形成数字图像。主要参数包括焦距、光圈、快门速度、ISO感光度等，这些参数影响图像的曝光、清晰度和噪声水平。</p>
<ul>
<li>焦距：镜头到图像传感器平面的距离，决定了摄像机的视角范围。</li>
<li>光圈：镜头中控制光线进入的孔径大小，影响图像的景深和光圈值。</li>
<li>快门速度：控制光线进入图像传感器的时间，影响图像的曝光时间。</li>
<li>ISO感光度：衡量图像传感器的敏感度，影响图像的噪声水平。</li>
</ul>
<p><strong>常见的图像和视频格式</strong>：包括JPEG、PNG、BMP、GIF、AVI、MP4等，这些格式有不同的压缩方式、颜色深度和用途。</p>
<ul>
<li>JPEG：有损压缩格式，适用于静态图像，支持高压缩比。</li>
<li>PNG：无损压缩格式，适用于静态图像，支持透明度。</li>
<li>BMP：无损压缩格式，适用于静态图像，支持高分辨率和颜色深度。</li>
<li>GIF：有损压缩格式，适用于动画图像，支持256色和透明度。</li>
<li>AVI：视频容器格式，支持多种编码方式，适用于高质量视频</li>
<li>MP4：视频容器格式，支持高压缩比和多种编码方式，适用于流媒体传输。</li>
<li>MKV：视频容器格式，支持多种编码方式和字幕，适用于高质量视频存储。</li>
</ul>
<h1 id="底层视觉1-图像处理-第4讲"><a href="#底层视觉1-图像处理-第4讲" class="headerlink" title="底层视觉1:图像处理(第4讲)"></a>底层视觉1:图像处理(第4讲)</h1><p><strong>图像的亮度</strong>：像素值的强度，通常表示为灰度值或RGB值。亮度可以通过加权平均法计算，例如：$Y &#x3D; 0.299R + 0.587G + 0.114B$。<br><strong>图像的对比度</strong>：图像中像素值的变化范围，通常通过计算图像的标准差或方差来衡量。对比度较高的图像具有较大的像素值变化范围，而对比度较低的图像则像素值变化较小。公式：$C &#x3D; \frac{I_{max} - I_{min}}{I_{max} + I_{min}}$，其中$I_{max}$和$I_{min}$分别为图像的最大和最小像素值。<br><strong>颜色空间与变换公式</strong>：常见的颜色空间包括RGB、HSV、Lab等。颜色空间变换公式如下：</p>
<ul>
<li>RGB到HSV变换：公式为<br>$H &#x3D; \begin{cases} 0, &amp; \text{if } C_{max} &#x3D; C_{min} \ 60 \times \frac{G - B}{C_{max} - C_{min}} + 360, &amp; \text{if } C_{max} &#x3D; R \ 60 \times \frac{B - R}{C_{max} - C_{min}} + 120, &amp; \text{if } C_{max} &#x3D; G \ 60 \times \frac{R - G}{C_{max} - C_{min}} + 240, &amp; \text{if } C_{max} &#x3D; B \end{cases}$，<br>$S &#x3D; \begin{cases} 0, &amp; \text{if } C_{max} &#x3D; 0 \ \frac{C_{max} - C_{min}}{C_{max}}, &amp; \text{otherwise} \end{cases}$，<br>$V &#x3D; C_{max}$，其中$C_{max}$和$C_{min}$分别为RGB中的最大值和最小值。</li>
</ul>
<p>举例：R &#x3D; 255, G &#x3D; 0, B &#x3D; 0，先将RGB归一化为(1,0,0)，则$C_{max} &#x3D; 1, C_{min} &#x3D; 0$，计算得$H &#x3D; 0, S &#x3D; 1, V &#x3D; 1$，即HSV为(0, 1, 1)。（H取值范围为0-360度，S和V取值范围为0-1。）</p>
<ul>
<li>HSV到RGB变换：公式为<br>$R &#x3D; C \times \max(0, \cos(\frac{\theta}{60} - 1)) + M$，<br>$G &#x3D; C \times \max(0, -\cos(\frac{\theta}{60} + 1)) + M$，<br>$B &#x3D; C \times \max(0, \cos(\frac{\theta}{60} + 3)) + M$，其中$C &#x3D; V \times S$，$M &#x3D; V \times (1 - S)$，$\theta$为H的值。</li>
</ul>
<p><strong>直方图均衡化</strong>：通过调整图像的灰度分布来增强图像对比度的方法。步骤包括计算图像的累积分布函数（CDF），然后使用CDF对原始图像进行映射。公式：$s_k &#x3D; (L - 1) \cdot \sum_{j&#x3D;0}^{k} \frac{n_j}{N}$，其中$s_k$为均衡化后的像素值，$L$为灰度级数，$n_j$为灰度级$j$的像素数，$N$为图像总像素数。</p>
<p>举例：假设一幅图像的灰度级为0-3，像素值分布为[0, 0, 1, 1, 2, 3]，则灰度级0的像素数为2，灰度级1的像素数为2，灰度级2的像素数为1，灰度级3的像素数为1，总像素数N&#x3D;6。计算累积分布函数（CDF）（其中像素个数依次<em>累加</em>，标准理论公式）：</p>
<ul>
<li>CDF(0) &#x3D; 2&#x2F;6 &#x3D; 0.333</li>
<li>CDF(1) &#x3D; (2+2)&#x2F;6 &#x3D; 0.666</li>
<li>CDF(2) &#x3D; (2+2+1)&#x2F;6 &#x3D; 0.833</li>
<li>CDF(3) &#x3D; (2+2+1+1)&#x2F;6 &#x3D; 1.0</li>
</ul>
<p>然后使用CDF进行映射，得到均衡化后的像素值（取整方法为四舍五入）：</p>
<ul>
<li>s(0) &#x3D; (4-1) * 0.333 &#x3D; 1</li>
<li>s(1) &#x3D; (4-1) * 0.666 &#x3D; 2</li>
<li>s(2) &#x3D; (4-1) * 0.833 &#x3D; 2</li>
<li>s(3) &#x3D; (4-1) * 1.0 &#x3D; 3</li>
</ul>
<p>均衡化后的图像像素值为[1, 1, 2, 2, 2, 3]。</p>
<p><strong>滤波</strong>：用于去除图像噪声和平滑图像的技术。常见的滤波方法包括：</p>
<ul>
<li>区域线性滤波：通过卷积操作实现图像平滑，如均值滤波和高斯滤波。<br>均值滤波卷积核示例：<br>$\begin{bmatrix} \frac{1}{9} &amp; \frac{1}{9} &amp; \frac{1}{9} \ \frac{1}{9} &amp; \frac{1}{9} &amp; \frac{1}{9} \ \frac{1}{9} &amp; \frac{1}{9} &amp; \frac{1}{9} \end{bmatrix}$<br>高斯滤波卷积核示例（σ&#x3D;1）：<br>$\begin{bmatrix} \frac{1}{16} &amp; \frac{2}{16} &amp; \frac{1}{16} \ \frac{2}{16} &amp; \frac{4}{16} &amp; \frac{2}{16} \ \frac{1}{16} &amp; \frac{2}{16} &amp; \frac{1}{16} \end{bmatrix}$，（σ&#x3D;标准差，决定模糊程度）</li>
<li>可分离滤波：将二维滤波器分解为两个一维滤波器，提高计算效率。<br>例如：高斯滤波器可以分解为水平和垂直方向的一维滤波器：<br>水平滤波器：<br>$\begin{bmatrix} \frac{1}{4} &amp; \frac{1}{2} &amp; \frac{1}{4} \end{bmatrix}$<br>垂直滤波器T：<br>$\begin{bmatrix} \frac{1}{4} &amp; \frac{1}{2} &amp; \frac{1}{4} \end{bmatrix}^T$</li>
<li>带通可控滤波：允许通过特定频率范围的滤波器。（适用于频域处理）</li>
<li>中值滤波：通过替换像素值为邻域内像素的中值来去除噪声。（适用于椒盐噪声）</li>
<li>双边滤波：同时考虑空间距离和像素值差异，实现边缘保留的平滑。（适用于去噪，特点是保留边缘）</li>
<li>图像引导滤波：利用引导图像的信息对输入图像进行平滑处理，保留边缘细节。（适用于图像增强和去噪）</li>
<li>laplacian滤波：通过计算图像的二阶导数来增强图像边缘。（适用于边缘检测）(例如：$\begin{bmatrix} 0 &amp; -1 &amp; 0 \ -1 &amp; 4 &amp; -1 \ 0 &amp; -1 &amp; 0 \end{bmatrix}$)</li>
<li>拉普拉斯金字塔：通过多次对图像进行高斯滤波和拉普拉斯滤波，得到不同尺度的图像金字塔。（适用于图像分割和特征提取、特征融合）</li>
<li>高斯金字塔：通过多次对图像进行高斯滤波，得到不同尺度的图像金字塔。（适用于图像分割和特征提取）</li>
<li>LoG滤波：通过计算图像的拉普拉斯高斯函数来增强图像边缘。（适用于边缘检测）</li>
<li>Canny边缘检测：通过计算图像的梯度方向和幅值，并结合非极大值抑制和双阈值检测来提取图像边缘。（适用于边缘检测）（卷积核示例：Sobel算子）：$\begin{bmatrix} -1 &amp; 0 &amp; 1 \ -2 &amp; 0 &amp; 2 \ -1 &amp; 0 &amp; 1 \end{bmatrix}$</li>
</ul>
<p><strong>二值形态学变换</strong>：用于处理二值图像的形态学操作，包括膨胀、腐蚀、开运算（先腐蚀后膨胀）、闭运算（先膨胀后腐蚀）等。</p>
<p><strong>小波变换</strong>：一种时频分析方法，通过多尺度分解提取图像特征，常用于图像压缩和去噪。计算题：对一维信号进行离散小波变换（DWT），假设信号为[4, 6, 10, 12]，使用Haar小波进行变换。步骤如下：</p>
<ol>
<li>计算平均值和差值：</li>
</ol>
<ul>
<li>平均值：[(4+6)&#x2F;2, (10+12)&#x2F;2] &#x3D; [5, 11]</li>
<li>差值：[(4-6)&#x2F;2, (10-12)&#x2F;2] &#x3D; [-1, -1]</li>
</ul>
<ol start="2">
<li>结果为：[5, 11, -1, -1]，其中前两个值为低频分量，后两个值为高频分量。<br>变换后相当于信号被分解为低频和高频部分，便于后续处理。</li>
</ol>
<h1 id="底层视觉2-模型拟合-第5讲"><a href="#底层视觉2-模型拟合-第5讲" class="headerlink" title="底层视觉2:模型拟合(第5讲)"></a>底层视觉2:模型拟合(第5讲)</h1><p><strong>插值模型</strong>：用于估计图像中未知像素值的方法。常见的插值方法包括最近邻插值、双线性插值、双三次插值等。</p>
<ul>
<li>最近邻插值：使用最接近的已知像素值进行插值。</li>
<li>双线性插值：使用四个最近邻像素值进行插值。</li>
<li>双三次插值：使用16个最近邻像素值进行插值，通常使用三次多项式进行插值。</li>
</ul>
<p><strong>常用径向基函数</strong>：径向基函数（RBF）是一种用于函数逼近和插值的数学工具，常见的RBF包括高斯函数、多项式函数和薄板样条函数等。</p>
<ul>
<li>高斯函数：$\phi(r) &#x3D; e^{-(\epsilon r)^2}$  ，其中 $r$ 为距离，$\epsilon$为形状参数。</li>
<li>多项式函数：$\phi(r) &#x3D; r^k$ ，$k$为多项式的阶数。</li>
<li>薄板样条函数：$\phi(r) &#x3D; r^2 \log(r)$，适用于二维插值问题。<br>使用方法：给定一组数据点，通过RBF构建插值函数，实现对未知点的估计。例如，使用高斯函数对一组数据点进行插值，可以构建一个高斯函数，使得该函数在已知数据点处取值为数据点的值，在未知点处取值为估计值。</li>
</ul>
<p><strong>能量最小化方法</strong>：通过定义能量函数并最小化该函数来实现图像处理任务的方法。常见的能量最小化方法包括变分法和马尔可夫随机场（MRF）模型等。<br>薄板样条也可用于能量最小化，通过最小化曲率能量实现平滑插值，</p>
<p><strong>变分方法、总变差</strong>：变分方法是一种通过优化能量函数来求解图像处理问题的数学工具。总变差（Total Variation, TV）是一种常用的能量函数，用于图像去噪和恢复。TV能量函数定义为：<br>$E(u) &#x3D; \int |\nabla u| , dx$<br>其中$u$为图像函数，$\nabla u$为图像的梯度。通过最小化TV能量函数，可以实现图像的平滑处理，同时保留边缘信息。</p>
<p><strong>马尔可夫随机场（MRF）模型</strong>：马尔可夫随机场是一种用于描述图像中像素间关系的概率图模型。MRF模型可以用于图像分割、图像去噪等任务。MRF模型通常由一组像素和一组像素间的依赖关系组成，通过定义像素的局部邻域和像素间的转移概率，实现对图像的建模和优化。例如，在图像分割任务中，MRF模型可以用于描述像素间的相似性和边界信息，通过优化能量函数实现对图像的分割。</p>
<h1 id="底层视觉3-运动估计-第6讲"><a href="#底层视觉3-运动估计-第6讲" class="headerlink" title="底层视觉3:运动估计(第6讲)"></a>底层视觉3:运动估计(第6讲)</h1><p><strong>鲁棒误差估计算子</strong>：用于处理含有异常值的数据，通过降低异常值对估计结果的影响，提高估计的鲁棒性。常见的鲁棒误差估计算子包括Huber损失函数、Tukey损失函数等。</p>
<ul>
<li>Huber损失函数：对于小误差使用平方损失，对于大误差使用线性损失。公式为：<br>$L_{\delta}(r) &#x3D; \begin{cases} \frac{1}{2} r^2, &amp; \text{if } |r| \leq \delta \ \delta (|r| - \frac{1}{2} \delta), &amp; \text{if } |r| &gt; \delta \end{cases}$</li>
<li>Tukey损失函数：对于小误差使用平方损失，对于大误差使用截断损失。公式为：<br>$L(r) &#x3D; \begin{cases} \frac{1}{2} r^2, &amp; \text{if } |r| \leq \delta \ \delta (|r| - \frac{1}{2} \delta), &amp; \text{if } |r| &gt; \delta \end{cases}$<br>其中$r$为估计误差，$\delta$为截断阈值。</li>
</ul>
<p><strong>光流！Lucas-Kanade算法</strong>：一种基于光流约束方程的局部运动估计算法，通过最小化图像亮度变化的平方误差来估计像素的运动矢量。算法步骤包括：</p>
<ol>
<li>计算图像梯度：计算图像在x和y方向的梯度。（例如图像卷积Sobel算子）</li>
<li>构建光流约束方程：基于图像亮度不变性假设，建立光流约束方程。</li>
<li>求解运动矢量：通过最小化光流约束方程的平方误差，求解运动矢量。步骤详解：<ul>
<li>在每个像素点的邻域内，构建光流约束方程的矩阵形式：<br>$\begin{bmatrix} I_x &amp; I_y \end{bmatrix} \begin{bmatrix} u \ v \end{bmatrix} &#x3D; -I_t$</li>
<li>通过最小二乘法求解上述方程，得到运动矢量$(u, v)$。</li>
</ul>
</li>
</ol>
<p>例题：假设在某个像素点处，图像梯度为$I_x &#x3D; 2, I_y &#x3D; 3, I_t &#x3D; -1$，则光流约束方程为：<br>$2u + 3v &#x3D; 1$<br>通过最小二乘法求解，得到运动矢量$(u, v)$。具体计算如下：</p>
<ul>
<li>构建矩阵形式：<br>$\begin{bmatrix} 2 &amp; 3 \end{bmatrix} \begin{bmatrix} u \ v \end{bmatrix} &#x3D; 1$</li>
<li>通过最小二乘法求解，得到：<br>$u &#x3D; \frac{3}{13}, v &#x3D; \frac{2}{13}$</li>
</ul>
<p><strong>仿射运动模型</strong>：一种描述图像中物体运动的数学模型，假设物体的运动可以通过仿射变换来表示。仿射运动模型包括平移、旋转、缩放和剪切等变换。仿射变换的数学表示为：<br>$\begin{bmatrix} x’ \ y’ \end{bmatrix} &#x3D; \begin{bmatrix} a_{11} &amp; a_{12} \ a_{21} &amp; a_{22} \end{bmatrix} \begin{bmatrix} x \ y \end{bmatrix} + \begin{bmatrix} t_x \ t_y \end{bmatrix}$<br>其中$(x, y)$为原始像素坐标，$(x’, y’)$为变换后的像素坐标，$a_{ij}$为仿射变换矩阵的元素，$t_x, t_y$为平移向量。</p>
<p><strong>光流计算公式及约束</strong>：光流是描述图像中像素运动的矢量场，常用的光流计算公式包括光流约束方程和光流平滑约束。光流约束方程基于图像亮度不变性假设，表示为：<br>$I_x u + I_y v + I_t &#x3D; 0$<br>其中$I_x, I_y$为图像在x和y方向的梯度，$I_t$为图像的时间梯度，$u, v$为像素的运动矢量。光流平滑约束用于保证光流场的连续性，通常通过最小化光流场的梯度来实现。</p>
<h1 id="中层视觉1-特征检测-第7讲"><a href="#中层视觉1-特征检测-第7讲" class="headerlink" title="中层视觉1:特征检测(第7讲)"></a>中层视觉1:特征检测(第7讲)</h1><p><strong>特征点的检测匹配</strong>：特征点检测是从图像中提取具有显著信息的点，常用的特征点检测算法包括Harris角点检测、SIFT特征点检测等。特征点匹配是将不同图像中的特征点进行对应，常用的匹配方法包括最近邻匹配、RANSAC算法等。</p>
<ul>
<li>Harris角点检测：通过计算图像梯度的协方差矩阵，检测图像中的角点。Harris角点检测包括计算图像梯度、构建协方差矩阵、计算响应函数和非极大值抑制等步骤。</li>
<li>SIFT特征点检测：通过尺度空间极值检测、关键点定位、方向分配和描述符生成等步骤，提取图像中的SIFT特征点。SIFT特征点具有尺度不变性和旋转不变性，常用于图像匹配和目标识别。</li>
<li>最近邻匹配：将一个图像中的特征点与另一个图像中的特征点进行匹配，选择距离最近的特征点作为匹配对。</li>
<li>RANSAC算法：一种用于处理含有异常值的匹配算法，通过迭代优化，选择最佳匹配对。RANSAC算法包括随机选择样本、构建模型、验证模型、迭代优化等步骤。</li>
</ul>
<p><strong>SIFT特征点的描述符</strong>：SIFT特征点描述符是用于描述SIFT特征点局部图像信息的向量，通常为128维。描述符通过计算特征点周围区域的梯度方向直方图来生成，具有旋转不变性和尺度不变性。描述符的计算步骤包括：</p>
<ol>
<li>计算特征点周围区域的梯度方向和幅值。（周围区域通常为16x16像素，计算每个像素的梯度方向和幅值）</li>
<li>将区域划分为4x4个子区域。（每个子区域为4x4像素）</li>
<li>对每个子区域计算8个方向的梯度直方图。（每个子区域的梯度方向范围为0-360度，划分为8个方向，每个方向对应45度的范围，计算每个方向上的梯度幅值总和，形成一个8维的直方图。对于每个像素，根据其梯度方向确定其所属的方向区间，然后将该像素的梯度幅值累加到对应的方向区间中，最后得到8个方向的梯度幅值总和，形成一个8维的直方图。如何计算每个像素的梯度方向和幅值：使用Sobel算子计算图像在x和y方向的梯度，公式为：$m(x,y) &#x3D; \sqrt{I_x^2 + I_y^2}$，$\theta(x,y) &#x3D; \tan^{-1}(\frac{I_y}{I_x})$，其中$I_x$和$I_y$分别为图像在x和y方向的梯度。）</li>
<li>将所有子区域的直方图连接成一个128维的描述符向量。（4x4个子区域，每个子区域8维，共128维）</li>
</ol>
<p><strong>特征点匹配的常用方法</strong>：特征点匹配是将不同图像中的特征点进行对应的方法，常用的匹配方法包括最近邻匹配、FLANN匹配等。</p>
<ul>
<li>最近邻匹配：将一个图像中的特征点与另一个图像中的特征点进行匹配，选择距离最近的特征点作为匹配对。</li>
<li>FLANN匹配：一种基于快速最近邻搜索算法的特征点匹配方法，通过构建索引树和k-d树等数据结构，提高匹配速度和精度。FLANN匹配包括构建索引、搜索最近邻、匹配筛选等步骤。</li>
</ul>
<h1 id="中层视觉2-图像分割-第8讲"><a href="#中层视觉2-图像分割-第8讲" class="headerlink" title="中层视觉2:图像分割(第8讲)"></a>中层视觉2:图像分割(第8讲)</h1><p><strong>OTSU算法</strong>：一种基于图像直方图的全局阈值分割方法，通过最大化类间方差来确定最佳阈值。算法步骤包括：</p>
<ol>
<li>计算图像的直方图和总像素数。（直方图表示每个灰度级出现的次数，总像素数为图像中像素的总数。）</li>
<li>遍历所有可能的阈值，计算类间方差。（对于每个阈值，将图像分为两个类：前景和背景。计算前景和背景的均值和方差，类间方差为前景和背景方差的加权和。公式为：<br>$\sigma_b^2(t) &#x3D; w_0(t) w_1(t) [\mu_0(t) - \mu_1(t)]^2$<br>其中$w_0(t)$为背景像素占总像素的比例，$w_1(t)&#x3D; 1 - w_0(t)$为前景像素占总像素的比例，$\mu_0(t)$为背景像素的平均灰度值，$\mu_1(t)$为前景像素的平均灰度值。）</li>
<li>选择使类间方差最大的阈值作为最佳阈值。</li>
</ol>
<p><strong>分水岭算法</strong>：一种基于图像梯度的分割方法，通过模拟水流在图像中的流动来划分区域。算法步骤包括：</p>
<ol>
<li>计算图像的梯度图。</li>
<li>识别梯度图中的局部极小值作为分割种子。</li>
<li>模拟水流从种子点向外扩展，直到遇到其他水流，形成分割边界。</li>
</ol>
<p><strong>Mean-Shift图像分割</strong>：一种基于密度估计的分割方法，通过迭代移动数据点到密度最大的位置来实现分割。算法步骤包括：</p>
<ol>
<li>初始化数据点和带宽参数。(带宽参数决定了邻域的大小，初始化的数据点是图像中的像素点，选取方法为随机选取或均匀分布。)</li>
<li>对每个数据点，计算其邻域内的密度估计。(使用核密度估计方法计算邻域内的密度。密度的含义是指在该点附近有多少数据点聚集，表示该区域的像素值分布情况。)</li>
<li>迭代移动数据点到密度最大的位置，直到收敛。(重复计算邻域内的密度估计，并更新数据点的位置，直到位置不再变化。)</li>
</ol>
<p><strong>图割算法的最优标记准则</strong>：图割算法是一种基于图论的全局分割方法，通过最小化图割的能量函数来实现分割。常用的最优标记准则包括最小割准则、最大流准则等。</p>
<ul>
<li>最小割准则：通过最小化图割的权重和来实现分割。详细步骤包括：</li>
</ul>
<ol>
<li>构建图模型：将图像中的像素点作为图的节点，像素间的相似性作为边的权重。</li>
<li>定义能量函数：能量函数包括数据项和光滑项，数据项表示像素与标签的匹配程度，光滑项表示相邻像素间标签的一致性。公式为：<br>$E(L) &#x3D; \sum_{p} D_p(L_p) + \sum_{(p,q) \in N} V_{p,q}(L_p, L_q)$<br>其中$L$为标签集合，$D_p(L_p)$为数据项，$V_{p,q}(L_p, L_q)$为光滑项，$N$为邻域关系。</li>
<li>最小化能量函数：通过图割算法求解最小割问题，得到最优标签分配。</li>
</ol>
<ul>
<li>最大流准则：通过最大化图中的流量来实现分割。详细步骤包括：</li>
</ul>
<ol>
<li>构建图模型：与最小割准则相同。</li>
<li>定义流量函数：流量函数表示从源节点到汇节点的最大流量。</li>
<li>最大化流量函数：通过最大流算法求解最大流问题，得到最优标签分配。</li>
</ol>
<h1 id="中层视觉3-特征配准和拼接-第9讲"><a href="#中层视觉3-特征配准和拼接-第9讲" class="headerlink" title="中层视觉3:特征配准和拼接(第9讲)"></a>中层视觉3:特征配准和拼接(第9讲)</h1><p><strong>最小二乘的二维配准</strong>：通过最小化配准误差的平方和来实现图像配准。配准误差定义为：<br>$E &#x3D; \sum_{i&#x3D;1}^{n} (x_i - x’_i)^2 + (y_i - y’_i)^2$<br>其中$(x_i, y_i)$为原始图像中的像素坐标，$(x’_i, y’_i)$为配准后的像素坐标，$n$为像素点的数量。通过最小化$E$，可以找到最佳的配准参数。</p>
<p><strong>鲁棒最小二乘法</strong>：通过引入鲁棒误差估计算子来提高最小二乘法的鲁棒性。常见的鲁棒误差估计算子包括Huber损失函数、Tukey损失函数等。例如，使用Huber损失函数，最小二乘问题可以重新表述为：<br>$\min_{\mathbf{x}} \sum_{i&#x3D;1}^{n} L_{\delta}(r_i)$<br>其中$r_i$为配准误差，$L_{\delta}$为Huber损失函数。通过最小化上述目标函数，可以得到鲁棒的最小二乘解。</p>
<p><strong>圆柱和球坐标系</strong>：用于表示三维空间中点的位置。圆柱坐标系使用径向距离$r$、角度$\theta$和高度$z$来表示点的位置，转换公式为：<br>$x &#x3D; r \cos\theta$，$y &#x3D; r \sin\theta$，$z &#x3D; z$。<br>球坐标系使用径向距离$r$、极角$\theta$和方位角$\phi$来表示点的位置，转换公式为：<br>$x &#x3D; r \sin\theta \cos\phi$，$y &#x3D; r \sin\theta \sin\phi$，$z &#x3D; r \cos\theta$。</p>
<p>**光束平差法(优化目标、视差去除)**：光束平差法是一种用于三维重建和摄像机姿态估计的优化方法，通过最小化观测误差来优化三维点和摄像机参数。优化目标通常定义为：<br>$E &#x3D; \sum_{i&#x3D;1}^{m} \sum_{j&#x3D;1}^{n} | p_{ij} - \hat{p}<em>{ij} |^2$<br>其中$p</em>{ij}$为观测点，$\hat{p}_{ij}$为重建点，$m$为摄像机数量，$n$为三维点数量。视差去除通过调整摄像机参数和三维点位置来减少观测误差，实现更准确的三维重建。<br><strong>常见的图像混合算法</strong>：用于将多张图像无缝拼接在一起的算法。常见的图像混合算法包括线性混合、多频段混合和泊松混合等。</p>
<ul>
<li>线性混合：通过线性加权的方式将多张图像进行混合。公式为：<br>$I(x, y) &#x3D; \sum_{i&#x3D;1}^{N} \alpha_i I_i(x, y)$<br>其中$N$为图像数量，$\alpha_i$为权重系数，$I_i(x, y)$为第$i$张图像在$(x, y)$位置的像素值。</li>
<li>多频段混合：将图像分解为多个频段，分别进行混合，再重构图像。多频段混合可以保留图像的细节信息，但计算复杂度较高。原理是通过对图像进行金字塔分解（通常使用高斯金字塔和拉普拉斯金字塔，他们的区别在于高斯金字塔是低通滤波，保留了图像的整体轮廓，而拉普拉斯金字塔是高通滤波，保留了图像的细节信息），分别对不同频段进行混合，最后将混合后的频段重构为最终图像。</li>
<li>泊松混合：通过求解泊松方程实现图像的无缝混合。泊松混合可以有效地处理图像边界处的颜色过渡问题，实现自然的混合效果。原理是用泊松方程来平滑图像边界处的颜色差异，从而实现无缝拼接。泊松混合的数学表达式为：<br>$\nabla^2 I &#x3D; \nabla \cdot \mathbf{v}$<br>其中$I$为混合后的图像，$\mathbf{v}$为图像梯度场。</li>
</ul>
<h1 id="高层视觉1-SfM和SLAM-第10讲"><a href="#高层视觉1-SfM和SLAM-第10讲" class="headerlink" title="高层视觉1:SfM和SLAM(第10讲)"></a>高层视觉1:SfM和SLAM(第10讲)</h1><p>相机标定指的是确定摄像机的内参和外参的过程。一般先进行内参标定，再进行外参标定。<br>内外参矩阵的表示如下：</p>
<ul>
<li>内参矩阵$K$：<br>$K &#x3D; \begin{bmatrix} f_x &amp; 0 &amp; c_x \ 0 &amp; f_y &amp; c_y \ 0 &amp; 0 &amp; 1 \end{bmatrix}$<br>其中$f_x$和$f_y$为摄像机在x和y方向的焦距，$c_x$和$c_y$为主点坐标。</li>
<li>外参矩阵$[R|t]$：<br>$[R|t] &#x3D; \begin{bmatrix} r_{11} &amp; r_{12} &amp; r_{13} &amp; t_x \ r_{21} &amp; r_{22} &amp; r_{23} &amp; t_y \ r_{31} &amp; r_{32} &amp; r_{33} &amp; t_z \end{bmatrix}$<br>其中$R$为旋转矩阵，描述摄像机坐标系相对于世界坐标系的旋转关系，$t$为平移向量，描述摄像机坐标系相对于世界坐标系的平移关系。</li>
</ul>
<p><strong>摄像机的外参估计</strong>：</p>
<p><strong>外部参数物理意义</strong>:<br>旋转矩阵$R$表示摄像机的朝向，描述了摄像机坐标系相对于世界坐标系的旋转关系。平移向量$t$表示摄像机的位置，描述了摄像机坐标系相对于世界坐标系的平移关系。</p>
<p><strong>外参估计方法</strong>：</p>
<ul>
<li><p><strong>直接线性变换（DLT）</strong>：通过建立投影矩阵与三维点和二维点之间的关系，求解外参。公式为：<br>$P &#x3D; K[R|t]$<br>其中$P$为投影矩阵，$K$为内参矩阵，$R$为旋转矩阵，$t$为平移向量。通过最小化重投影误差，可以求解外参。<br>直接线性变换（DLT）是一种用于估计摄像机外参的方法，通过建立投影矩阵与三维点和二维点之间的关系，求解外参。</p>
<p>具体例题：假设已知三维点$X &#x3D; [X, Y, Z, 1]^T$和对应的二维点$x &#x3D; [u, v, 1]^T$，通过DLT方法可以构建线性方程组：</p>
</li>
</ul>
<p>$\begin{bmatrix} u P_{3}^T - P_{1}^T \ v P_{3}^T - P_{2}^T \end{bmatrix} \begin{bmatrix} R \ t \end{bmatrix} &#x3D; 0$<br>通过最小二乘法求解上述方程组，得到摄像机的外参$R$和$t$。</p>
<ul>
<li><p><strong>三角测量</strong>：通过多个摄像机视图中的对应点，利用几何关系计算三维点的位置。公式为：<br>$X &#x3D; (P_1^T P_1)^{-1} P_1^T P_2 x$<br>三角测量是通过两个或多个摄像机视图中的对应点，利用几何关系计算三维空间中点的位置。</p>
<p>具体例题：假设有两个摄像机视图，摄像机1的投影矩阵为$P_1$，摄像机2的投影矩阵为$P_2$，对应的二维点分别为$x_1$和$x_2$。通过三角测量方法，可以构建线性方程组：</p>
</li>
</ul>
<p>$\begin{bmatrix} x_1 P_{1,3}^T - P_{1,1}^T \ y_1 P_{1,3}^T - P_{1,2}^T \ x_2 P_{2,3}^T - P_{2,1}^T \ y_2 P_{2,3}^T - P_{2,2}^T \end{bmatrix} X &#x3D; 0$<br>通过最小二乘法求解上述方程组，得到三维点$X$的位置。</p>
<p><strong>摄像机的内参估计</strong>：<br>摄像机的内部参数描述了摄像机的光学特性和成像过程。内参包括焦距$f$、主点坐标$(c_x, c_y)$和畸变参数等。</p>
<p><strong>一般过程</strong>: 包括拍摄标定板图像，提取特征点，建立投影模型，求解内参。</p>
<p>焦距估计公式为：<br>$f &#x3D; \frac{d \cdot s}{D}$<br>其中$d$为摄像机到标定板的距离，$s$为标定板上特征点的实际尺寸，$D$为图像中对应特征点的像素距离。</p>
<p>畸变估计公式包括径向畸变和切向畸变，常用的径向畸变模型为：<br>$x_{distorted} &#x3D; x(1 + k_1 r^2 + k_2 r^4 + k_3 r^6)$，<br>$y_{distorted} &#x3D; y(1 + k_1 r^2 + k_2 r^4 + k_3 r^6)$<br>其中$(x, y)$为未畸变的像素坐标，$(x_{distorted}, y_{distorted})$为畸变后的像素坐标，$r$为像素点到主点的距离，$k_1, k_2, k_3$为径向畸变系数。</p>
<p><strong>极线几何约束</strong>：极线几何描述了两个摄像机视图中对应点之间的关系。对于一个图像中的点，其对应点必须位于另一个图像中的极线上。极线方程为：<br>$l’ &#x3D; F \cdot p$<br>其中$l’$为极线，$F$为基础矩阵，$p$为图像中的点。极线几何约束可以用于立体匹配和三维重建。</p>
<p><strong>光束平差法在SLAM中的应用</strong>：光束平差法在SLAM中用于同时优化摄像机的位姿和地图点的位置。通过最小化观测误差，实现对摄像机轨迹和环境地图的精确估计。光束平差法包括以下步骤：</p>
<ol>
<li>构建观测模型：建立摄像机位姿和地图点位置与观测点之间的关系。</li>
<li>定义能量函数：能量函数包括观测误差和先验信息。</li>
<li>最小化能量函数：通过非线性优化方法求解最小化问题，得到最优的摄像机位姿和地图点位置。</li>
</ol>
<p><strong>SfM和SLAM的区别</strong>：SfM（Structure from Motion）和SLAM（Simultaneous Localization and Mapping）都是用于估计摄像机位姿和地图点位置的方法，但它们的应用场景和目标有所不同。</p>
<ul>
<li>SfM：主要用于从多个摄像机视图重建三维场景，不需要事先知道摄像机的位姿。它通过分析多个视图中的对应点，利用几何关系计算三维点的位置和摄像机的位姿。SfM的目标是重建三维场景，包括场景的结构和摄像机位姿。</li>
<li>SLAM：主要用于实时估计摄像机的位姿和构建环境地图，通常应用于机器人导航和增强现实等领域。SLAM需要在未知环境中同时进行定位和地图构建，目标是实现实时的位姿估计和环境感知。</li>
</ul>
<p><strong>SLAM系统的整体组成</strong>：</p>
<ul>
<li>传感器数据获取：获取摄像机的图像数据或激光雷达点云数据等。通常使用SIFT、ORB等特征点检测算法，提取图像中的特征点，并进行匹配，找到不同帧之间的对应关系。</li>
<li>特征提取与匹配：从图像或点云中提取特征点，并进行特征匹配，找到不同帧之间的对应关系。</li>
<li>位姿估计：利用特征匹配结果，估计摄像机的位姿变化。通过PnP算法、ICP算法等方法，估计摄像机的位姿变化。</li>
<li>地图构建：根据位姿估计结果，构建环境地图，包括三维点云、纹理地图等。利用三角测量、体素网格等方法，构建环境地图。</li>
<li>优化与闭环检测：对地图和位姿进行优化，并检测闭环，以实现地图的完整性和一致性。使用图优化、非线性最小二乘等方法，对地图和位姿进行优化，提高精度。通过识别已经访问过的场景，实现地图的闭环，减少累积误差。</li>
</ul>
<h1 id="高层视觉2-深度估计-第11讲"><a href="#高层视觉2-深度估计-第11讲" class="headerlink" title="高层视觉2:深度估计(第11讲)"></a>高层视觉2:深度估计(第11讲)</h1><p><strong>对应关系的相似度度量，对应关系建立算法的主要模块</strong>：对应关系的相似度度量用于评估两个图像块之间的相似程度，常用的度量方法包括SSD（Sum of Squared Differences）、SAD（Sum of Absolute Differences）和归一化互相关（NCC）。对应关系建立算法的主要模块包括特征提取、特征匹配和优化处理。</p>
<ul>
<li>SSD：计算两个图像块像素值差的平方和，公式为：<br>$SSD &#x3D; \sum_{i,j} (I_1(i,j) - I_2(i,j))^2$</li>
<li>SAD：计算两个图像块像素值差的绝对值和，公式为：<br>$SAD &#x3D; \sum_{i,j} |I_1(i,j) - I_2(i,j)|$</li>
<li>NCC：计算两个图像块的归一化互相关，公式为：<br>$NCC &#x3D; \frac{\sum_{i,j} (I_1(i,j) - \bar{I_1})(I_2(i,j) - \bar{I_2})}{\sqrt{\sum_{i,j} (I_1(i,j) - \bar{I_1})^2 \sum_{i,j} (I_2(i,j) - \bar{I_2})^2}}$<br>其中$I_1$和$I_2$为两个图像块，$\bar{I_1}$和$\bar{I_2}$为图像块的平均值。</li>
</ul>
<p>**对应关系全局优化方法有哪些?**：常见的对应关系全局优化方法包括图割优化、动态规划和信念传播等。</p>
<ul>
<li>图割优化：通过构建图模型，最小化能量函数实现对应关系的全局优化。</li>
<li>动态规划：通过递归分解问题，利用子问题的最优解构建全局最优解。</li>
<li>信念传播：通过在图模型中传递信息，实现对应关系的全局优化。</li>
</ul>
<p>**三维形状表示方法(深度图、网格、点云、图像块云、体积模型)**：</p>
<ul>
<li>深度图：每个像素存储对应点的深度值，适用于单目深度估计。</li>
<li>网格：通过连接三维点形成多边形网格，适用于三维模型表示。</li>
<li>点云：由大量三维点组成，适用于三维扫描和重建。</li>
<li>图像块云：将图像块作为三维点的集合，适用于纹理映射。</li>
<li>体积模型：通过体素表示三维空间，适用于医学成像和科学计算。</li>
</ul>
<p>**多视几何误差估计基本方法(公式)**：多视几何误差估计常用的方法包括重投影误差和三维点误差。</p>
<ul>
<li>重投影误差：衡量三维点投影到图像平面上的误差，公式为：<br>$E_{reproj} &#x3D; \sum_{i&#x3D;1}^{n} | p_i - \hat{p}_i |^2$<br>其中$p_i$为观测点，$\hat{p}_i$为重投影点，$n$为点的数量。</li>
<li>三维点误差：衡量三维点位置的误差，公式为：<br>$E_{3D} &#x3D; \sum_{i&#x3D;1}^{n} | P_i - \hat{P}_i |^2$<br>其中$P_i$为真实三维点，$\hat{P}_i$为估计的三维点，$n$为点的数量。</li>
</ul>
<p><strong>单目深度估计方法分类</strong>：单目深度估计方法根据所采用的模型和算法可以分为以下几类：基于几何的方法、基于学习的方法和基于优化的方法。</p>
<ul>
<li>基于几何的方法：通过几何关系计算深度，如立体视觉、光流和结构光等。</li>
<li>基于学习的方法：利用深度学习模型进行深度估计，如深度神经网络和卷积神经网络等。</li>
<li>基于优化的方法：通过优化目标函数进行深度估计，如光束平差法和最小二乘法等。</li>
</ul>
<h1 id="高层视觉3-三维重建-第12讲"><a href="#高层视觉3-三维重建-第12讲" class="headerlink" title="高层视觉3:三维重建(第12讲)"></a>高层视觉3:三维重建(第12讲)</h1><p>**可用于恢复三维模型的信息(明暗、纹理、焦点……)**：用于三维重建的信息包括：</p>
<ul>
<li>明暗信息：通过分析图像中的光照变化，恢复物体的表面形状。</li>
<li>纹理信息：利用图像中的纹理特征，增强三维模型的细节表现。</li>
<li>焦点信息：通过焦点变化，估计物体的深度信息。</li>
<li>轮廓信息：通过提取物体的轮廓，辅助三维模型的构建。</li>
<li>运动信息：通过分析物体的运动，恢复三维结构。</li>
</ul>
<p>**三维成像设备原理分类(结构光、时间飞行法……)**：</p>
<ul>
<li>结构光成像：通过投射已知结构的光图案，利用图案变形恢复三维形状。</li>
<li>时间飞行法（ToF）：通过测量光信号从发射到接收的时间，计算物体的深度信息。</li>
<li>立体视觉：通过两个或多个摄像机视图，利用视差计算三维结构。</li>
<li>激光扫描：通过激光束扫描物体表面，获取高精度的三维点云数据。</li>
<li>多视图重建：通过多个视角的图像，结合几何关系恢复三维模型。</li>
</ul>
<p>**三维结构表示方法及优缺点(基于点、线、面、体的表示)**：</p>
<ul>
<li>基于点的表示（点云）：优点云表示简单，易于获取，但缺乏表面信息，难以表达连续性。</li>
<li>基于线的表示（线框模型）：优点能够表达物体的边界和结构，但难以表示复杂表面。</li>
<li>基于面的表示（网格模型）：优点能够表达物体的表面形状，适用于渲染，但计算复杂度较高。</li>
<li>基于体的表示（体素模型）：优点能够表达复杂的三维结构，适用于医学成像，但存储空间需求大。</li>
</ul>
<h1 id="高层视觉4-图像识别-第13讲"><a href="#高层视觉4-图像识别-第13讲" class="headerlink" title="高层视觉4:图像识别(第13讲)"></a>高层视觉4:图像识别(第13讲)</h1><p><strong>图像识别的各项任务定义及相互关系</strong>：</p>
<ul>
<li>图像分类：将图像分配到预定义的类别中。</li>
<li>目标检测：在图像中定位并识别特定目标。</li>
<li>语义分割：为图像中的每个像素分配类别标签。</li>
<li>实例分割：不仅分配类别标签，还区分同类别的不同实例。</li>
<li>关系：图像分类是基础任务，目标检测和语义分割在分类基础上进行扩展，实例分割结合了目标检测和语义分割的特点。</li>
</ul>
<p><strong>每种任务的经典模型</strong>：</p>
<ul>
<li>图像分类：经典模型包括AlexNet、VGG、ResNet等。</li>
<li>目标检测：经典模型包括R-CNN、Fast R-CNN、Faster R-CNN、YOLO、SSD等。</li>
<li>语义分割：经典模型包括FCN、U-Net、DeepLab等。</li>
<li>实例分割：经典模型包括Mask R-CNN等。</li>
</ul>
<h1 id="计算机视觉-X-第14讲"><a href="#计算机视觉-X-第14讲" class="headerlink" title="计算机视觉+X(第14讲)"></a>计算机视觉+X(第14讲)</h1><p><strong>计算摄影学的概念</strong>: 是新兴的交叉研究领域，旨在通过可计算的图像获取、处理和操纵技术，将软硬件有机结合起来，克服传统数码相机的局限性，实现对图像能力的增强或扩展。主要研究方向包括：</p>
<ul>
<li>光度校正（Photometric Calibration）：目标是校准测量或记录光强度的设备，确保获取数据准确反映实际光度量，通过1、相机响应函数（CRF）标定：将相机接收到的场景辐射度转换为图像像素亮度值；2、晕影效应校正：图像外围亮度比中心区域低的现象校正。</li>
<li>高动态范围成像（HDR）：亮的地方更亮，暗的地方更暗，亮度跨度很大，实现比普通数字图像技术更大曝光的动态范围，可以在一张照片中呈现更大的明暗差别（避免曝光不足或过度曝光）</li>
<li>图像超分辨率：提升图像分辨率，从低分辨率图像生成高分辨率图像，通过算法恢复丢失的细节信息</li>
<li>图像抠图：从背景中分离前景对象，实现精确的前景提取</li>
<li>图像合成：将多个图像组合成一个新图像，包括纹理分析与合成</li>
</ul>
<p><strong>CV+CG的主要任务</strong>: CV+CG的主要任务包括：</p>
<ul>
<li>视图插值：从已知视角生成新视角的图像，用于虚拟现实和增强现实应用</li>
<li>分层深度图像：为图像中的不同对象分配深度信息，用于3D重建和场景理解</li>
<li>光场和发光图：光场技术记录光线的方向和强度，发光图用于高效渲染光照效果</li>
<li>环境遮罩：从图像中提取物体与背景的边界信息，用于图像合成和场景编辑</li>
<li>视频渲染：将计算机生成的3D模型实时渲染为视频，用于游戏、电影特效和虚拟现实</li>
</ul>
<p><strong>CV+NLP为什么要结合</strong>：视觉和语言是人类获取信息的两大主要渠道，结合CV和NLP可以实现更全面的信息理解。计算机视觉（CV）和自然语言处理（NLP）的结合有助于实现更智能的系统，如图像描述生成、视觉问答等。通过结合视觉和语言信息，系统能够更好地理解和解释图像内容。</p>
<p><strong>AGI的理解</strong>:<br>AGI（Artificial General Intelligence）指的是具备广泛认知能力的人工智能系统，能够像人类一样理解和处理各种任务，而不仅仅是执行特定任务。是一种通用人工智能，能解决一般问题，具备推理和主动学习能力。<br>ANI（Artificial Narrow Intelligence）：专用人工智能，解决特定问题（如人脸识别、图像分类）；ASI（Artificial Super Intelligence）：超级人工智能，超越人类智能。我们目前仍处于ANI阶段，需要从专用智能向通用智能发展，CV+X（X&#x3D;CG、NLP等）是实现AGI的必经之路。</p>
<h1 id="计算题"><a href="#计算题" class="headerlink" title="计算题"></a>计算题</h1><ol>
<li><p>相机内参矩阵的计算：假设已知摄像机的焦距$f$，主点坐标$(c_x, c_y)$，则摄像机的内参矩阵$K$可以表示为：<br>$K &#x3D; \begin{bmatrix} f &amp; 0 &amp; c_x \ 0 &amp; f &amp; c_y \ 0 &amp; 0 &amp; 1 \end{bmatrix}$</p>
</li>
<li><p>相机外参矩阵的计算：假设已知摄像机的旋转矩阵$R$和平移向量$t$，则摄像机的外参矩阵$[R|t]$可以表示为：<br>$[R|t] &#x3D; \begin{bmatrix} R &amp; t \ 0 &amp; 1 \end{bmatrix}$</p>
</li>
<li><p>视差与深度的关系：假设有一个立体摄像机系统，基线长度为$B$，焦距为$f$，视差为$d$，则深度$Z$可以通过以下公式计算：<br>$Z &#x3D; \frac{fB}{d}$<br>其中，$f$为焦距，$B$为基线长度，$d$为视差。</p>
</li>
<li><p>投影变换的计算：假设有一个三维点$P &#x3D; (X, Y, Z)$，摄像机的内参矩阵为$K$，外参矩阵为$[R|t]$，则该点在图像平面上的投影点$p &#x3D; (u, v)$可以通过以下公式计算：<br>$p &#x3D; K [R|t] P$<br>具体计算步骤包括：</p>
</li>
</ol>
<ul>
<li>将三维点$P$转换为齐次坐标形式：$P_{h} &#x3D; (X, Y, Z, 1)$</li>
<li>计算摄像机坐标系下的点：$P_{c} &#x3D; [R|t] P_{h}$</li>
<li>计算图像平面上的投影点：$p_{h} &#x3D; K P_{c}$</li>
<li>将齐次坐标转换为非齐次坐标：$u &#x3D; \frac{p_{h,x}}{p_{h,z}}, v &#x3D; \frac{p_{h,y}}{p_{h,z}}$</li>
</ul>
<ol start="5">
<li><p>计算图像的灰度值：假设有一个RGB图像的像素值为$(R, G, B)$，可以通过以下公式计算其灰度值$Y$：<br>$Y &#x3D; 0.299R + 0.587G + 0.114B$<br>其中$R, G, B$分别为红、绿、蓝通道的像素值。 </p>
</li>
<li><p>计算图像的直方图均衡化：假设有一个灰度图像，其像素值范围为0-255，可以通过以下步骤进行直方图均衡化(OpenCV实用公式)：</p>
</li>
</ol>
<ul>
<li>计算图像的直方图$h(i)$，其中$i$为像素值。</li>
<li>计算累积分布函数（CDF）：$c(i) &#x3D; \sum_{j&#x3D;0}^{i} h(j)$</li>
<li>归一化CDF：$c_{norm}(i) &#x3D; \frac{c(i) - c_{min}}{N - c_{min}} \times 255$<br>其中$c_{min}$为非零CDF的最小值，$N$为图像的总像素数。</li>
<li>使用归一化的CDF映射原始像素值，得到均衡化后的图像。</li>
</ul>
<ol start="7">
<li><p>计算图像的傅里叶变换：假设有一个二维图像$f(x, y)$，其傅里叶变换$F(u, v)$可以通过以下公式计算：<br>$F(u, v) &#x3D; \sum_{x&#x3D;0}^{M-1} \sum_{y&#x3D;0}^{N-1} f(x, y) e^{-j2\pi(\frac{ux}{M} + \frac{vy}{N})}$<br>其中$M$和$N$分别为图像的宽度和高度，$j$为虚数单位。 </p>
</li>
<li><p>滤波计算：将卷积核的每个元素与图像的对应元素相乘，然后求和，得到滤波后的像素值。在边界处，可以使用零填充或镜像填充等方法处理。关于卷积核是否归一化的问题，通常情况下，卷积核需要进行归一化处理，以确保滤波后的图像亮度不会发生显著变化。归一化的方法是将卷积核的所有元素之和归一化为1，即：<br>$K_{norm}(i,j) &#x3D; \frac{K(i,j)}{\sum_{m,n} K(m,n)}$<br>其中$K(i,j)$为卷积核的元素，$K_{norm}(i,j)$为归一化后的卷积核元素。10. </p>
</li>
<li><p>Harris角点响应计算：假设有一个图像$I(x, y)$，可以通过以下步骤计算Harris角点响应R值：</p>
</li>
</ol>
<ul>
<li>计算图像的梯度：$I_x &#x3D; \frac{\partial I}{\partial x}, I_y &#x3D; \frac{\partial I}{\partial y}$</li>
<li>计算矩阵M的元素：$M &#x3D; \begin{bmatrix} I_x^2 &amp; I_x I_y \ I_x I_y &amp; I_y^2 \end{bmatrix}$</li>
<li>计算矩阵M的特征值$\lambda_1$和$\lambda_2$。（计算特征值的方法：对于2x2矩阵$M &#x3D; \begin{bmatrix} a &amp; b \ b &amp; c \end{bmatrix}$，其特征值可以通过求解特征方程$|M - \lambda I| &#x3D; 0$得到，即：<br>$\lambda^2 - (a + c)\lambda + (ac - b^2) &#x3D; 0$，解出$\lambda_1$和$\lambda_2$）</li>
<li>计算Harris角点响应R值：$R &#x3D; \lambda_1 \lambda_2 - k(\lambda_1 + \lambda_2)^2$<br>其中$k$为经验常数，通常取值为0.04-0.06。最终R值越大，表示该点越可能是角点。</li>
</ul>
<ol start="10">
<li>对极几何计算：假设有两个相机$C_1$和$C_2$，它们的内参矩阵分别为$K_1$和$K_2$，外参矩阵分别为$[R_1|t_1]$和$[R_2|t_2]$，可以通过以下步骤计算基础矩阵$F$：</li>
</ol>
<ul>
<li>计算相机的投影矩阵：$P_1 &#x3D; K_1[R_1|t_1]$，$P_2 &#x3D; K_2[R_2|t_2]$。</li>
<li>计算基础矩阵：$F &#x3D; K_2^{-T}E K_1^{-1}$，其中$E$为本质矩阵，可以通过$E &#x3D; [t]_x R$计算得到。</li>
<li>极线方程：对于图像上的一个点$p_1$，其在另一幅图像上的极线方程为$l_2 &#x3D; F p_1$。</li>
</ul>
<h1 id="补充"><a href="#补充" class="headerlink" title="补充"></a>补充</h1><p><strong>内参 vs 外参</strong>：内参描述相机内部属性，外参描述相机姿态<br><strong>基础矩阵 vs 本质矩阵</strong>：他们都描述两个视图间的几何关系，基础矩阵适用于未校正图像，本质矩阵适用于校正图像<br><strong>SIFT vs SURF vs ORB</strong>：SIFT最稳定但慢，SURF较快，ORB最快，他们都是特征点检测和描述算法<br><strong>SSD vs NCC</strong>：SSD对亮度敏感，NCC对亮度变化鲁棒，NCC计算复杂度高，适用于光照变化大的场景，他们都是图像配准算法，用于将一张图像中的特征点与另一张图像中的对应点匹配。<br><strong>图像分类 vs 目标检测 vs 实例分割</strong>：分类：整图类别；检测：定位+分类（边界框）；实例分割：像素级分类+实例区分<br><strong>SfM vs SLAM</strong>：SfM（Structure from Motion）：离线，多视图，高精度重建；SLAM（Simultaneous Localization and Mapping）：在线，实时，定位与建图<br><strong>传统方法 vs 深度学习方法</strong>：传统：特征工程+机器学习 深度学习：端到端学习，特征自动提取<br><strong>经典CNN架构</strong>：AlexNet：首个成功CNN，ReLU，Dropout，数据增强；VGG：小卷积核（3×3），深层网络；ResNet：残差连接，解决梯度消失；U-Net：编码器-解码器，跳跃连接，用于分割；YOLO：单阶段检测，将检测视为回归问题;<br><strong>损失函数</strong>：分类：交叉熵损失；检测：Smooth L1损失（边框回归），Focal Loss（处理类别不平衡）；分割：Dice Loss，BCE损失；<br><strong>评价指标</strong>：分类：准确率，精确率，召回率，F1分数；检测：mAP（平均精度均值），IoU；分割：mIoU（平均交并比），像素精度。</p>
<div id="paginator"></div></div><div id="post-footer"><div id="pages"><div class="footer-link" style="width: 50%;text-align:right;border-right:1px #fe2 solid"><a href="/2025/11/22/Tech/GAME/%E4%BB%8EUnity%E5%88%B0UE%E7%9A%84%E6%97%A9%E6%9C%9F%E7%BB%8F%E9%AA%8C%E6%80%BB%E7%BB%93/">← 下一篇 从Unity到UE的早期经验总结</a></div><div class="footer-link" style="width: 50%;right:1px;border-left:1px #fe2 solid"><a href="/2025/11/22/Tech/%E7%AE%97%E6%B3%95/C++%E8%AE%B0%E5%BF%86%E7%9F%A5%E8%AF%86%E7%82%B9/">C++记忆知识点 上一篇 →</a></div></div></div></div><div class="bottom-btn"><div><a class="i-top" id="to-top" onClick="scrolls.scrolltop();" title="回到顶部" style="opacity: 0; display: none;">∧ </a><a class="i-index" id="to-index" href="#toc-div" title="文章目录">≡</a><a class="i-color" id="color-mode" onClick="colorMode.change()" title="切换主题"></a><a onclick="BgmControl()"><svg id="bgm-control" viewBox="0 0 30 34" fill="currentColor" style="width: 24px; transition: transform .3s;margin-top: 4px"><path d="M25.998 23.422V11.29h3.999v12.132h-3.999zM19.497 6.234h4.001v22.243h-4.001V6.234zM12.998.867h4v32.978h-4V.867zm-6.5 5.367h4.001v22.243H6.498V6.234zm-6.5 5.056h4v12.132h-4V11.29z"></path></svg><audio id="bgm" src="/audio/bgm.mp3" loop crossorigin="anonymous"> </audio></a></div></div></article><aside><div id="about"><a href="/" id="logo"><img src="/img/faction/amiya.png" alt="Logo" style="margin:0;border-radius:0;"></a><h1 id="Dr"><a href="/">Nervld Island™</a></h1><div id="description"><p></p></div><div id="social-links"><a class="social" target="_blank" rel="noopener" href="https://github.com/RuspeciaNervld"><i class="fab fa-github" alt="GitHub"></i></a><a class="social" href="mailto:WindNegev@gmail.com"><i class="fa fa-envelope" alt="E-Mail"></i></a><a class="social" target="_blank" rel="noopener" href="https://space.bilibili.com/245123239"><i class="fa-brands fa-bilibili" alt="BiliBili"></i></a><a class="social" target="_blank" rel="noopener" href="https://www.zhihu.com/people/warfarin-40"><i class="fab fa-zhihu" alt="Zhihu"></i></a></div></div><div id="aside-block"><div id="toc-div"><h1>目录</h1><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89%E5%9F%BA%E7%A1%80-%E7%AC%AC2%E8%AE%B2"><span class="toc-number">1.</span> <span class="toc-text">计算机视觉基础(第2讲)</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%9B%BE%E5%83%8F%E7%9A%84%E5%BD%A2%E6%88%90-%E7%AC%AC3%E8%AE%B2"><span class="toc-number">2.</span> <span class="toc-text">图像的形成(第3讲)</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%BA%95%E5%B1%82%E8%A7%86%E8%A7%891-%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86-%E7%AC%AC4%E8%AE%B2"><span class="toc-number">3.</span> <span class="toc-text">底层视觉1:图像处理(第4讲)</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%BA%95%E5%B1%82%E8%A7%86%E8%A7%892-%E6%A8%A1%E5%9E%8B%E6%8B%9F%E5%90%88-%E7%AC%AC5%E8%AE%B2"><span class="toc-number">4.</span> <span class="toc-text">底层视觉2:模型拟合(第5讲)</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%BA%95%E5%B1%82%E8%A7%86%E8%A7%893-%E8%BF%90%E5%8A%A8%E4%BC%B0%E8%AE%A1-%E7%AC%AC6%E8%AE%B2"><span class="toc-number">5.</span> <span class="toc-text">底层视觉3:运动估计(第6讲)</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E4%B8%AD%E5%B1%82%E8%A7%86%E8%A7%891-%E7%89%B9%E5%BE%81%E6%A3%80%E6%B5%8B-%E7%AC%AC7%E8%AE%B2"><span class="toc-number">6.</span> <span class="toc-text">中层视觉1:特征检测(第7讲)</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E4%B8%AD%E5%B1%82%E8%A7%86%E8%A7%892-%E5%9B%BE%E5%83%8F%E5%88%86%E5%89%B2-%E7%AC%AC8%E8%AE%B2"><span class="toc-number">7.</span> <span class="toc-text">中层视觉2:图像分割(第8讲)</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E4%B8%AD%E5%B1%82%E8%A7%86%E8%A7%893-%E7%89%B9%E5%BE%81%E9%85%8D%E5%87%86%E5%92%8C%E6%8B%BC%E6%8E%A5-%E7%AC%AC9%E8%AE%B2"><span class="toc-number">8.</span> <span class="toc-text">中层视觉3:特征配准和拼接(第9讲)</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E9%AB%98%E5%B1%82%E8%A7%86%E8%A7%891-SfM%E5%92%8CSLAM-%E7%AC%AC10%E8%AE%B2"><span class="toc-number">9.</span> <span class="toc-text">高层视觉1:SfM和SLAM(第10讲)</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E9%AB%98%E5%B1%82%E8%A7%86%E8%A7%892-%E6%B7%B1%E5%BA%A6%E4%BC%B0%E8%AE%A1-%E7%AC%AC11%E8%AE%B2"><span class="toc-number">10.</span> <span class="toc-text">高层视觉2:深度估计(第11讲)</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E9%AB%98%E5%B1%82%E8%A7%86%E8%A7%893-%E4%B8%89%E7%BB%B4%E9%87%8D%E5%BB%BA-%E7%AC%AC12%E8%AE%B2"><span class="toc-number">11.</span> <span class="toc-text">高层视觉3:三维重建(第12讲)</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E9%AB%98%E5%B1%82%E8%A7%86%E8%A7%894-%E5%9B%BE%E5%83%8F%E8%AF%86%E5%88%AB-%E7%AC%AC13%E8%AE%B2"><span class="toc-number">12.</span> <span class="toc-text">高层视觉4:图像识别(第13讲)</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89-X-%E7%AC%AC14%E8%AE%B2"><span class="toc-number">13.</span> <span class="toc-text">计算机视觉+X(第14讲)</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E8%AE%A1%E7%AE%97%E9%A2%98"><span class="toc-number">14.</span> <span class="toc-text">计算题</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E8%A1%A5%E5%85%85"><span class="toc-number">15.</span> <span class="toc-text">补充</span></a></li></ol></div></div><footer><nobr>构建自 <a target="_blank" rel="noopener" href="http://hexo.io">Hexo</a></nobr><wbr><nobr> 使用主题 <a target="_blank" rel="noopener" href="https://github.com/Yue-plus/hexo-theme-arknights">Arknights</a></nobr><wbr><nobr> 主题作者 <a target="_blank" rel="noopener" href="https://github.com/Yue-plus">Yue_plus</a></nobr></footer></aside></main><canvas id="canvas-dust"></canvas></body></html>